{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "634192c7-dc32-49a9-9299-db791b775719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.1.1-cp39-cp39-win_amd64.whl (10.8 MB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4; python_version < \"3.11\" in c:\\program files\\python39\\lib\\site-packages (from pandas) (1.24.2)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: tzdata, six, python-dateutil, pytz, pandas\n",
      "Successfully installed pandas-2.1.1 python-dateutil-2.8.2 pytz-2023.3.post1 six-1.16.0 tzdata-2023.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07bd8cf4-1778-4f3b-a7b2-44c8d881cda7",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'train_gan_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------------Training [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m model_name)\n\u001b[0;32m     65\u001b[0m utils\u001b[38;5;241m.\u001b[39mprint_params(args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m], args[model_name])\n\u001b[1;32m---> 67\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43minit_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m G \u001b[38;5;241m=\u001b[39m GeneratorMNIST(z_dim)\n\u001b[0;32m     70\u001b[0m DG \u001b[38;5;241m=\u001b[39m DGWGAN32()\n",
      "File \u001b[1;32mC:\\gmi_attack\\Jupiter\\projects\\GMI\\background\\utils.py:101\u001b[0m, in \u001b[0;36minit_dataloader\u001b[1;34m(args, file_path, batch_size, mode)\u001b[0m\n\u001b[0;32m     99\u001b[0m     data_set \u001b[38;5;241m=\u001b[39m dataloader\u001b[38;5;241m.\u001b[39mImageFolder(args, file_path, mode)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMNIST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 101\u001b[0m     data_set \u001b[38;5;241m=\u001b[39m \u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGrayFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(data_set,\n\u001b[0;32m    104\u001b[0m                                           batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    105\u001b[0m                                           shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m                                           num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m    107\u001b[0m                                           pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    109\u001b[0m interval \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m tf\n",
      "File \u001b[1;32mC:\\gmi_attack\\Jupiter\\projects\\GMI\\background\\dataloader.py:18\u001b[0m, in \u001b[0;36mGrayFolder.__init__\u001b[1;34m(self, args, file_path, mode)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_list \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_path)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_processor()\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_list, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_img()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_list)\n",
      "File \u001b[1;32mC:\\gmi_attack\\Jupiter\\projects\\GMI\\background\\dataloader.py:26\u001b[0m, in \u001b[0;36mGrayFolder.get_list\u001b[1;34m(self, file_path)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path):\n\u001b[0;32m     25\u001b[0m     name_list, label_list \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m---> 26\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mreadlines():\n\u001b[0;32m     28\u001b[0m         img_name, iden \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'train_gan_file'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import utils\n",
    "import torch\n",
    "import dataloader\n",
    "import torchvision\n",
    "from utils import *\n",
    "from torch.nn import BCELoss\n",
    "from torch.autograd import grad\n",
    "import torchvision.utils as tvls\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from discri import DGWGAN32\n",
    "from generator import GeneratorMNIST\n",
    "\n",
    "def freeze(net):\n",
    "    for p in net.parameters():\n",
    "        p.requires_grad_(False) \n",
    "\n",
    "def unfreeze(net):\n",
    "    for p in net.parameters():\n",
    "        p.requires_grad_(True)\n",
    "\n",
    "def gradient_penalty(x, y):\n",
    "    # interpolation\n",
    "    shape = [x.size(0)] + [1] * (x.dim() - 1)\n",
    "    alpha = torch.rand(shape).cuda()\n",
    "    z = x + alpha * (y - x)\n",
    "    z = z.cuda()\n",
    "    z.requires_grad = True\n",
    "\n",
    "    o = DG(z)\n",
    "    g = grad(o, z, grad_outputs = torch.ones(o.size()).cuda(), create_graph = True)[0].view(z.size(0), -1)\n",
    "    gp = ((g.norm(p = 2, dim = 1) - 1) ** 2).mean()\n",
    "\n",
    "    return gp\n",
    "\n",
    "root_path = \"./\"\n",
    "log_path = os.path.join(root_path, \"attack_logs\")\n",
    "save_img_dir = os.path.join(root_path, \"MNIST//trainingSet\")\n",
    "save_model_dir= os.path.join(root_path, \"attack_models\")\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_img_dir, exist_ok=True)\n",
    "os.makedirs(log_path, exist_ok=True)\n",
    "\n",
    "dataset_name = \"MNIST\"\n",
    "\n",
    "log_file = \"GAN.txt\"\n",
    "utils.Tee(os.path.join(log_path, log_file), 'w')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    file = \"./MNIST.json\"\n",
    "    args = load_json(json_file=file)\n",
    "\n",
    "    file_path = 'train_gan_file'\n",
    "    model_name = 'GAN'\n",
    "    lr = args[model_name]['lr']\n",
    "    batch_size = args[model_name]['batch_size']\n",
    "    z_dim = args[model_name]['z_dim']\n",
    "    epochs = args[model_name]['epochs']\n",
    "    n_critic = args[model_name]['n_critic']\n",
    "\n",
    "    print(\"---------------------Training [%s]------------------------------\" % model_name)\n",
    "    utils.print_params(args[\"dataset\"], args[model_name])\n",
    "\n",
    "    dataloader = init_dataloader(args, file_path, batch_size, mode=\"gan\")\n",
    "\n",
    "    G = GeneratorMNIST(z_dim)\n",
    "    DG = DGWGAN32()\n",
    "    \n",
    "    G = torch.nn.DataParallel(G).cuda()\n",
    "    DG = torch.nn.DataParallel(DG).cuda()\n",
    "\n",
    "    dg_optimizer = torch.optim.Adam(DG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    g_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "    step = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        for i, imgs in enumerate(dataloader):\n",
    "            step += 1\n",
    "            imgs = imgs.cuda()\n",
    "            bs = imgs.size(0)\n",
    "            \n",
    "            freeze(G)\n",
    "            unfreeze(DG)\n",
    "\n",
    "            z = torch.randn(bs, z_dim).cuda()\n",
    "            f_imgs = G(z)\n",
    "\n",
    "            r_logit = DG(imgs)\n",
    "            f_logit = DG(f_imgs)\n",
    "            \n",
    "            wd = r_logit.mean() - f_logit.mean()  # Wasserstein-1 Distance\n",
    "            gp = gradient_penalty(imgs.data, f_imgs.data)\n",
    "            dg_loss = - wd + gp * 10.0\n",
    "            \n",
    "            dg_optimizer.zero_grad()\n",
    "            dg_loss.backward()\n",
    "            dg_optimizer.step()\n",
    "\n",
    "            # train G\n",
    "\n",
    "            if step % n_critic == 0:\n",
    "                freeze(DG)\n",
    "                unfreeze(G)\n",
    "                z = torch.randn(bs, z_dim).cuda()\n",
    "                f_imgs = G(z)\n",
    "                logit_dg = DG(f_imgs)\n",
    "                # calculate g_loss\n",
    "                g_loss = - logit_dg.mean()\n",
    "                \n",
    "                g_optimizer.zero_grad()\n",
    "                g_loss.backward()\n",
    "                g_optimizer.step()\n",
    "\n",
    "        end = time.time()\n",
    "        interval = end - start\n",
    "        print(\"Epoch:%d \\t Time:%.2f\" % (epoch, interval))\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            z = torch.randn(32, z_dim).cuda()\n",
    "            fake_image = G(z)\n",
    "            save_tensor_images(fake_image.detach(), os.path.join(save_img_dir, \"result_image_{}.png\".format(epoch)), nrow = 8)\n",
    "        \n",
    "        torch.save({'state_dict':G.state_dict()}, os.path.join(save_model_dir, \"MNIST_G.tar\"))\n",
    "        torch.save({'state_dict':DG.state_dict()}, os.path.join(save_model_dir, \"MNIST_D.tar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647257f4-0a4d-455b-8ce8-cf824a39f840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
